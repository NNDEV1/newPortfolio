{"status":"ok","feed":{"url":"https://medium.com/feed/@nalinnagar1","title":"Stories by Nalin Nagar on Medium","link":"https://medium.com/@nalinnagar1?source=rss-eb61516296cc------2","author":"","description":"Stories by Nalin Nagar on Medium","image":"https://cdn-images-1.medium.com/fit/c/150/150/1*js9C1T9kUjBp_28iSvAe0A.jpeg"},"items":[{"title":"How I Made my Own NFTs with Deep Learning","pubDate":"2022-02-25 16:16:11","link":"https://medium.com/analytics-vidhya/how-i-made-my-own-nfts-with-deep-learning-9266232b9c13?source=rss-eb61516296cc------2","guid":"https://medium.com/p/9266232b9c13","author":"Nalin Nagar","thumbnail":"https://cdn-images-1.medium.com/max/1024/1*Rir2-o_Bcc_u1xXIstOEKw.gif","description":"\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*Rir2-o_Bcc_u1xXIstOEKw.gif\"></figure><p>Non-fungible tokens (NFTs) represent a type of cryptocurrency that is unique and indivisible. Each NFT has unique characteristics and values, and they often come in limited quantities represented through different data formats such as MP4, JPG, or\u00a0PDF.</p>\n<p>Crypto and blockchain are upcoming technologies and so is deep learning. Combining these two technologies could yield an interesting results. I decided to try it out and started brainstorming unique usage of deep learning and\u00a0NFT.</p>\n<p>I came up with idea of of crypto art. Utilizing the logo representing of cryptocurrencies such as Ethereum and Bitcoin and turning it into unique pieces of art using deep learning\u00a0models.</p>\n<p>The deep learning part was going to be turning these logos into some form of art that was creative and unique. Creativity needs to be dervided from a deep learning model. I searched for models in a open sea of deep learning papers. Finally I found what seemed to be what I needed: Stylized Neural Painting(<a href=\"https://arxiv.org/abs/2011.08114\">Link to\u00a0paper</a>).</p>\n<h3>What is Stylized Neural Painting?</h3>\n<p>Creating paintings in one of the ways humans are able to define and express themselves. With Stylized Neural Painting this process is automated and looks humanly natural with its progressive strokes.</p>\n<p>You might already be thinking a GAN architecture is behind this, but you would be wrong. Most generative networks make use of pixel-wise mapping or continuous optimization methods in their architecture however this paper adds another dimension to this type of generation with the idea of stroke prediction.</p>\n<p>Stroke prediction is a parameter searching process that aims to maximize the similarity between the input image and its given \u201ccanvas\u201d. Another change implemented is a rasterization network and a shading network instead of your usual generator and discriminators. The proposed renderer better deals with the disentanglement of the shape and color, and this new architecture outperforms other methods of painting with deep learning by a large\u00a0margin.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*jijLcgq5ijjM2SBvGUgEdw.png\"><figcaption>Network Architecture (<a href=\"https://arxiv.org/pdf/2011.08114.pdf\">https://arxiv.org/pdf/2011.08114.pdf</a>)</figcaption></figure><p>The soft blending is defined as\u00a0follows:</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/787/1*Uvuy7D6S7-qsXJNooENbmQ.png\"><figcaption>Soft blending</figcaption></figure><p>Where <em>h</em> is the canvas, \u03b1 is defined as the alpha matte, and <em>s</em> is defined as the stroke foreground.</p>\n<p>Gradient descent is used to update the strokes and is defined as\u00a0follows:</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/735/1*HwnCw9Yw7b67cf7IspSMeQ.png\"><figcaption>Gradient descent</figcaption></figure><p>Suppose <em>h</em> of <em>T</em> is the canvas and <em>h hat</em> is the reference picture<em> </em>and, \u2112 is a loss function that minimizes differences in h of T and h hat, <em>x</em> is the collection of all stroke parameters, and \u00b5 is a predefined learning\u00a0rate.</p>\n<p>This optimization used to optimize the model architecture mentioned below:</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/681/1*s-My1mB6kRst9kVbdpTaMw.png\"><figcaption>Shading network and rasterization network architecture</figcaption></figure><p>These model parameters can be optimized for different types of strokes including oil pastel, watercolor, markerpen, and box/rectangle, and I made use of this which I will explain later. This is a very basic overview of Neural Stylized Painting and if you want a deeper dive into what is actually going on I recommend reading the paper and looking through the code which I will link\u00a0below:</p>\n<p><a href=\"https://github.com/jiupinjia/stylized-neural-painting\">GitHub - jiupinjia/stylized-neural-painting: Official Pytorch implementation of the preprint paper \"Stylized Neural Painting\", in CVPR 2021.</a></p>\n<p>Arxiv: <a href=\"https://arxiv.org/pdf/2011.08114.pdf\">https://arxiv.org/pdf/2011.08114.pdf</a></p>\n<h4>How Did I Make Use of the\u00a0Model?</h4>\n<p>I used their code implementation on Github and pretrained models that the creators so kindly provided to provide unique inputs to create various\u00a0NFTs.</p>\n<h3>OpenSea and Posting the\u00a0NFTs</h3>\n<p>After I had gotten all the code working, all I had to do was pick base image,\u00a0, choose a style, and set a few hyperparameters to get the final\u00a0result.</p>\n<p>The output was progressive painting in gif form depecting painting strokes and making the NFT look even cooler. Below are some unique and vogue GIFs that I created with my idea of making crypto themed\u00a0art:</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/512/1*60x7Tj85MQnLtmHtGCvM3w.gif\"><figcaption>BitLocker with Box Style by\u00a0Author</figcaption></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/512/1*T8XN03_4st68HTRK_P1vig.gif\"><figcaption>EthHandOG with Oil Pastel Style by\u00a0Author</figcaption></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/512/1*O2dIPu8MVI344zsUTzo1AA.gif\"><figcaption>BlueEth with MarkerPen Style by\u00a0Author</figcaption></figure><p>I needed to find a place to mint the NFTs and post them for sale for art lovers. For this I chose the platform OpenSea. OpenSea is a peer-to-peer marketplace for NFTs where you can buy, sell, and auction your digital collectibles. OpenSea makes it extremely easy to mint your NFTs and then post them for\u00a0auction.</p>\n<p>I decided to name my collection CryptoArt AI.</p>\n<h3>What Did I\u00a0Learn?</h3>\n<p>I learned a ton about both of these upcoming technologies from this project and I\u2019m excited to use them even\u00a0more.</p>\n<p>Stylized Neural Painting redefined how we think about art generation in the world of deep learning which opens the door for many new exciting possibilities. Learning about this new architecture and looking through the actual code implementation helped me learn a lot about the new rasterization and shading architecture which I could possibly use in the future for my own personal endeavors.</p>\n<p>Learning how to use OpenSea was also a critical step in learning the new technologies that are fueling our world today. I\u2019m excited to post new NFTs on OpenSea, and possibly list them for sale(stay tuned!). I am most excited to learn about code development in a blockchain environment and its\u00a0usages.</p>\n<p>What do you think of this article and the technology used? I would love to hear and connect with you on these\u00a0topics.</p>\n<p>Links:</p>\n<p>My OpenSea Collection: <a href=\"https://opensea.io/collection/cryptoart-ai\">https://opensea.io/collection/cryptoart-ai</a>(Check it out and if you find it interesting give it a like and if you\u2019re a collector it\u2019s also for\u00a0sale.)</p>\n<ul>\n<li><a href=\"https://github.com/NNDEV1\">NNDEV1 - Overview</a></li>\n<li><a href=\"https://github.com/jiupinjia/stylized-neural-painting\">GitHub - jiupinjia/stylized-neural-painting: Official Pytorch implementation of the preprint paper \"Stylized Neural Painting\", in CVPR 2021.</a></li>\n</ul>\n<p>Stylized Neural Painting: <a href=\"https://arxiv.org/pdf/2011.08114.pdf\">https://arxiv.org/pdf/2011.08114.pdf</a></p>\n<p>Discord Server for NFTs: <a href=\"https://discord.gg/hHW2kSzp\">https://discord.gg/hHW2kSzp</a></p>\n<p>My Personal Website: <a href=\"https://personal-website-nndev1.vercel.app/\">https://personal-website-nndev1.vercel.app/</a></p>\n<h4>Thanks for Reading and do give me few claps if you like the contents of this\u00a0article!</h4>\n<img src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=9266232b9c13\" width=\"1\" height=\"1\" alt=\"\"><hr>\n<p><a href=\"https://medium.com/analytics-vidhya/how-i-made-my-own-nfts-with-deep-learning-9266232b9c13\">How I Made my Own NFTs with Deep Learning</a> was originally published in <a href=\"https://medium.com/analytics-vidhya\">Analytics Vidhya</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>\n","content":"\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*Rir2-o_Bcc_u1xXIstOEKw.gif\"></figure><p>Non-fungible tokens (NFTs) represent a type of cryptocurrency that is unique and indivisible. Each NFT has unique characteristics and values, and they often come in limited quantities represented through different data formats such as MP4, JPG, or\u00a0PDF.</p>\n<p>Crypto and blockchain are upcoming technologies and so is deep learning. Combining these two technologies could yield an interesting results. I decided to try it out and started brainstorming unique usage of deep learning and\u00a0NFT.</p>\n<p>I came up with idea of of crypto art. Utilizing the logo representing of cryptocurrencies such as Ethereum and Bitcoin and turning it into unique pieces of art using deep learning\u00a0models.</p>\n<p>The deep learning part was going to be turning these logos into some form of art that was creative and unique. Creativity needs to be dervided from a deep learning model. I searched for models in a open sea of deep learning papers. Finally I found what seemed to be what I needed: Stylized Neural Painting(<a href=\"https://arxiv.org/abs/2011.08114\">Link to\u00a0paper</a>).</p>\n<h3>What is Stylized Neural Painting?</h3>\n<p>Creating paintings in one of the ways humans are able to define and express themselves. With Stylized Neural Painting this process is automated and looks humanly natural with its progressive strokes.</p>\n<p>You might already be thinking a GAN architecture is behind this, but you would be wrong. Most generative networks make use of pixel-wise mapping or continuous optimization methods in their architecture however this paper adds another dimension to this type of generation with the idea of stroke prediction.</p>\n<p>Stroke prediction is a parameter searching process that aims to maximize the similarity between the input image and its given \u201ccanvas\u201d. Another change implemented is a rasterization network and a shading network instead of your usual generator and discriminators. The proposed renderer better deals with the disentanglement of the shape and color, and this new architecture outperforms other methods of painting with deep learning by a large\u00a0margin.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*jijLcgq5ijjM2SBvGUgEdw.png\"><figcaption>Network Architecture (<a href=\"https://arxiv.org/pdf/2011.08114.pdf\">https://arxiv.org/pdf/2011.08114.pdf</a>)</figcaption></figure><p>The soft blending is defined as\u00a0follows:</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/787/1*Uvuy7D6S7-qsXJNooENbmQ.png\"><figcaption>Soft blending</figcaption></figure><p>Where <em>h</em> is the canvas, \u03b1 is defined as the alpha matte, and <em>s</em> is defined as the stroke foreground.</p>\n<p>Gradient descent is used to update the strokes and is defined as\u00a0follows:</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/735/1*HwnCw9Yw7b67cf7IspSMeQ.png\"><figcaption>Gradient descent</figcaption></figure><p>Suppose <em>h</em> of <em>T</em> is the canvas and <em>h hat</em> is the reference picture<em> </em>and, \u2112 is a loss function that minimizes differences in h of T and h hat, <em>x</em> is the collection of all stroke parameters, and \u00b5 is a predefined learning\u00a0rate.</p>\n<p>This optimization used to optimize the model architecture mentioned below:</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/681/1*s-My1mB6kRst9kVbdpTaMw.png\"><figcaption>Shading network and rasterization network architecture</figcaption></figure><p>These model parameters can be optimized for different types of strokes including oil pastel, watercolor, markerpen, and box/rectangle, and I made use of this which I will explain later. This is a very basic overview of Neural Stylized Painting and if you want a deeper dive into what is actually going on I recommend reading the paper and looking through the code which I will link\u00a0below:</p>\n<p><a href=\"https://github.com/jiupinjia/stylized-neural-painting\">GitHub - jiupinjia/stylized-neural-painting: Official Pytorch implementation of the preprint paper \"Stylized Neural Painting\", in CVPR 2021.</a></p>\n<p>Arxiv: <a href=\"https://arxiv.org/pdf/2011.08114.pdf\">https://arxiv.org/pdf/2011.08114.pdf</a></p>\n<h4>How Did I Make Use of the\u00a0Model?</h4>\n<p>I used their code implementation on Github and pretrained models that the creators so kindly provided to provide unique inputs to create various\u00a0NFTs.</p>\n<h3>OpenSea and Posting the\u00a0NFTs</h3>\n<p>After I had gotten all the code working, all I had to do was pick base image,\u00a0, choose a style, and set a few hyperparameters to get the final\u00a0result.</p>\n<p>The output was progressive painting in gif form depecting painting strokes and making the NFT look even cooler. Below are some unique and vogue GIFs that I created with my idea of making crypto themed\u00a0art:</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/512/1*60x7Tj85MQnLtmHtGCvM3w.gif\"><figcaption>BitLocker with Box Style by\u00a0Author</figcaption></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/512/1*T8XN03_4st68HTRK_P1vig.gif\"><figcaption>EthHandOG with Oil Pastel Style by\u00a0Author</figcaption></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/512/1*O2dIPu8MVI344zsUTzo1AA.gif\"><figcaption>BlueEth with MarkerPen Style by\u00a0Author</figcaption></figure><p>I needed to find a place to mint the NFTs and post them for sale for art lovers. For this I chose the platform OpenSea. OpenSea is a peer-to-peer marketplace for NFTs where you can buy, sell, and auction your digital collectibles. OpenSea makes it extremely easy to mint your NFTs and then post them for\u00a0auction.</p>\n<p>I decided to name my collection CryptoArt AI.</p>\n<h3>What Did I\u00a0Learn?</h3>\n<p>I learned a ton about both of these upcoming technologies from this project and I\u2019m excited to use them even\u00a0more.</p>\n<p>Stylized Neural Painting redefined how we think about art generation in the world of deep learning which opens the door for many new exciting possibilities. Learning about this new architecture and looking through the actual code implementation helped me learn a lot about the new rasterization and shading architecture which I could possibly use in the future for my own personal endeavors.</p>\n<p>Learning how to use OpenSea was also a critical step in learning the new technologies that are fueling our world today. I\u2019m excited to post new NFTs on OpenSea, and possibly list them for sale(stay tuned!). I am most excited to learn about code development in a blockchain environment and its\u00a0usages.</p>\n<p>What do you think of this article and the technology used? I would love to hear and connect with you on these\u00a0topics.</p>\n<p>Links:</p>\n<p>My OpenSea Collection: <a href=\"https://opensea.io/collection/cryptoart-ai\">https://opensea.io/collection/cryptoart-ai</a>(Check it out and if you find it interesting give it a like and if you\u2019re a collector it\u2019s also for\u00a0sale.)</p>\n<ul>\n<li><a href=\"https://github.com/NNDEV1\">NNDEV1 - Overview</a></li>\n<li><a href=\"https://github.com/jiupinjia/stylized-neural-painting\">GitHub - jiupinjia/stylized-neural-painting: Official Pytorch implementation of the preprint paper \"Stylized Neural Painting\", in CVPR 2021.</a></li>\n</ul>\n<p>Stylized Neural Painting: <a href=\"https://arxiv.org/pdf/2011.08114.pdf\">https://arxiv.org/pdf/2011.08114.pdf</a></p>\n<p>Discord Server for NFTs: <a href=\"https://discord.gg/hHW2kSzp\">https://discord.gg/hHW2kSzp</a></p>\n<p>My Personal Website: <a href=\"https://personal-website-nndev1.vercel.app/\">https://personal-website-nndev1.vercel.app/</a></p>\n<h4>Thanks for Reading and do give me few claps if you like the contents of this\u00a0article!</h4>\n<img src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=9266232b9c13\" width=\"1\" height=\"1\" alt=\"\"><hr>\n<p><a href=\"https://medium.com/analytics-vidhya/how-i-made-my-own-nfts-with-deep-learning-9266232b9c13\">How I Made my Own NFTs with Deep Learning</a> was originally published in <a href=\"https://medium.com/analytics-vidhya\">Analytics Vidhya</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>\n","enclosure":{},"categories":["deep-learning","blockchain","nft","machine-learning","opensea"]},{"title":"Text Summarization with Transformers","pubDate":"2021-07-07 01:05:02","link":"https://nalinnagar1.medium.com/abstractive-text-summarization-with-transformers-b6967d1892ec?source=rss-eb61516296cc------2","guid":"https://medium.com/p/b6967d1892ec","author":"Nalin Nagar","thumbnail":"https://cdn-images-1.medium.com/max/1024/0*mehIeV8W32jDZc3i","description":"\n<p>How to use transformers to summarize text.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*mehIeV8W32jDZc3i\"><figcaption>Photo by <a href=\"https://unsplash.com/@hirmin?utm_source=medium&amp;utm_medium=referral\">Max Kleinen</a> on\u00a0<a href=\"https://unsplash.com/?utm_source=medium&amp;utm_medium=referral\">Unsplash</a></figcaption></figure><p>Transformers are an incredibly powerful tool in the world of NLP. The invention of the transformer was a revolutionary discovery for NLP and the field of machine learning. Today, we see the transformer architecture being used for everything from neural machine translation to image classification. Let's explore how transformers can be used for abstractive text summarization.</p>\n<p>Let\u2019s get started on the tutorial.</p>\n<h4>The first step is to import the various libraries that we will be\u00a0using.</h4>\n<a href=\"https://medium.com/media/408e757204bf8a84dfdd2277537e3dab/href\">https://medium.com/media/408e757204bf8a84dfdd2277537e3dab/href</a><p>We import <em>pandas</em> for the data preprocessing and <em>NumPy</em> for linear\u00a0algebra.</p>\n<p>In this tutorial instead of using <em>PyTorch</em>, I used <em>PyTorch Lightning</em>. We import Dataset and DataLoader from <em>PyTorch</em> so we can create the\u00a0dataset.</p>\n<p>We also import <em>ModelCheckpoint</em> so we can save our model for later\u00a0use.</p>\n<p>From transformers, we will import <em>T5ForConditionalGeneration</em> for the model, <em>AdamW</em> for the optimizer, and <em>T5Tokenizer</em> for the tokenizer.</p>\n<p>The dataset I will be using is the \u201cNEWS SUMMARY\u201d dataset from Kaggle(<a href=\"https://www.kaggle.com/sunnysai12345/news-summary\">https://www.kaggle.com/sunnysai12345/news-summary</a>). <em>Pandas</em> is used to load and preprocess our\u00a0data.</p>\n<a href=\"https://medium.com/media/0b8a35ae057f4e825a9fa5c87b8585c2/href\">https://medium.com/media/0b8a35ae057f4e825a9fa5c87b8585c2/href</a><p>Once the dataframe is loaded we create a new dataframe only using the relevant data needed. I then created a new dataframe and transposed it so the data is column-wise instead of row-wise.</p>\n<p>I also renamed the columns to identify which column has the summary and which one has the source text. Now, drop the nonexistent values and then split the data into a train set and a test\u00a0set.</p>\n<p>Lastly, print out the shape of the dataset making sure that everything looks\u00a0correct.</p>\n<h4>Next, create the PyTorch\u00a0dataset.</h4>\n<p>The code snippet for the dataset is shown\u00a0below:</p>\n<a href=\"https://medium.com/media/6164896957b2e977fef176334c9e1595/href\">https://medium.com/media/6164896957b2e977fef176334c9e1595/href</a><p>As shown in the code snippet above the <em>SummaryDataset</em> class takes four arguments i.e. the tokenizer, the dataframe, source text\u2019s max token length, and summary\u2019s max token length. Using the arguments we will create a text encoding using the tokenizer.</p>\n<p>Now grab the specified row from the dataframe and create the source text\u2019s encoding and then the summary\u2019s encoding. This method eventually returns a dictionary with all the\u00a0data.</p>\n<p>Next, create a PyTorch Lightning Data Module that takes in the test and train dataframe, the source text\u2019s max token length, and the summary\u2019s max token length, the tokenizer, and finally the batch size. In the setup method, the dataset object that we created before is called. Finally, in the dataloader methods, we return the DataLoader of the dataset we\u00a0created.</p>\n<h4>The next step is to define our\u00a0model.</h4>\n<a href=\"https://medium.com/media/bcc32256efe2124c9fabfb8865e05c61/href\">https://medium.com/media/bcc32256efe2124c9fabfb8865e05c61/href</a><p>In the code above I define the model name. The model being used is the \u201ct5-base\u201d model from <em>huggingface. </em>Next, I fetch the pre-trained tokenizer using the specified model name. I then define the number of epochs and our batch\u00a0size.</p>\n<p>Then we build our data module using the batch size, tokenizer, and the train and test data. Next, define the <em>SummaryModel</em> class. I fetch the pre-trained <em>T5ForConditionalGeneration</em> model and call\u00a0it.</p>\n<p>After the model is defined we need to define the training step. First, define the base step method. Grab the input ids, text attention mask, labels, and labels attention mask from the batch and pass all of those arguments into the model, then log the loss. From this base method, we can define the train, validation, and test steps. For the optimizer, return the AdamW optimizer with a learning rate of\u00a0<em>1e-4</em>.</p>\n<h4>Now comes the training of the\u00a0model.</h4>\n<a href=\"https://medium.com/media/4d7ea18b7eaedb23c81cec0dc1850288/href\">https://medium.com/media/4d7ea18b7eaedb23c81cec0dc1850288/href</a><p>In the code above I define the <em>ModelCheckpoint </em>class<em> </em>so it can periodically save checkpoints for future use of the model. Now define a <em>PyTorch Lightning Trainer</em> and pass in the <em>ModelCheckpoint</em> callback, the epochs, GPUs, and the progress bar refresh rate. We fit the trainer with the model and the data module. And there it is, the model is now training!</p>\n<h4>After your model is done training, it\u2019s time to make some predictions!</h4>\n<p>The code snippet is down\u00a0below:</p>\n<a href=\"https://medium.com/media/b1e08a970e904cf12be79609c6b86965/href\">https://medium.com/media/b1e08a970e904cf12be79609c6b86965/href</a><p>First, load the model checkpoint and then freeze the model for a faster prediction. To get the summary, define the summarize function that takes in the text we want to summarize. Into the generate method, pass in the input ids, the attention mask, and the max_length from the generated ids.</p>\n<p><strong>The rest of the hyper-parameters are values that can be fine-tuned.</strong></p>\n<p><strong>If you aren\u2019t happy with the results, try fine-tuning the hyper-parameters.</strong></p>\n<p>Then decode the generated values with the tokenizer which will return the predicted text. After this, return the predictions joined by a space and the summarize function is finished. Now we can test our model with the test dataframe. If you aren\u2019t getting your desired results you can also try training the model for\u00a0longer.</p>\n<p>Here is the snippet of the Result I got\u00a0:</p>\n<blockquote>\n<strong><em>Source Text:</em></strong> The Indian Navy today moved towards acquiring a pin-point ability to attack targets on land with its first test of the land-attack variant of the BrahMos supersonic cruise missile. The missile has a range of 400km.\\xa0 The successive successful launch of the supersonic missile took place at sea off the Andaman and Nicobar islands. This is the first time a land-attack variant of the missile was fired from a warship and also the first sea-to-land missile test in the country. HERE\u2019S ALL YOU NEED TO KNOW:1. The missile fired from the ship squarely hit the specially created land target put up in one of the islands of Andaman and Nicobar. 2. According to officials of the Indo-Russian BrahMos corporation, the missile met all flight parameters during the test where it selected the designated target among the group of targets, hitting it precisely and destroying the target with its tremendous kinetic energy.3. The Navy has already inducted anti-ship versions of the BrahMos on its warships including the Rajput and is integrating them into two other ships of the class. 4. The missiles will also equip the three 7000-ton Kolkata class destroyers currently under construction at the Mazagon Docks Ltd, Mumbai. 5. The Indian Navy began inducting the first version of the BrahMos Missile System in all of its frontline warships from 2005. BrahMos can be launched in single or in a salvo from the ship towards single or different types of targets within an interval of 2\u20132.5 seconds in various trajectories.</blockquote>\n<blockquote>\n<strong><em>Summary Prediction:</em></strong> The Indian Navy on Tuesday launched its first land-attack variant of the BrahMos supersonic cruise missile, which has a range of 400 km. The missile was fired from a warship off the Andaman and Nicobar islands in India. It met all flight parameters during the test where it selected the designated target among the group of targets, hitting it precisely and destroying the target with its tremendous kinetic\u00a0energy.</blockquote>\n<p>Now you have built an abstractive text summarizer using transformers! If you want to learn more about other methods of text summarization, refer to my past article(<a href=\"https://nalinnagar1.medium.com/how-to-make-a-simple-text-summarizer-cf4eb2d0df4a\">https://nalinnagar1.medium.com/how-to-make-a-simple-text-summarizer-cf4eb2d0df4a</a>)</p>\n<p>Let me know what you think of the approach taken in this tutorial. I would be glad to hear ways to improve and any other topics that I should make an article about.<br>Lastly, I am here to learn and share, and any suggestions for improvements are more than\u00a0welcome.</p>\n<p>Otherwise, see you in my next.\u00a0Ciao.</p>\n<img src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=b6967d1892ec\" width=\"1\" height=\"1\" alt=\"\">\n","content":"\n<p>How to use transformers to summarize text.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*mehIeV8W32jDZc3i\"><figcaption>Photo by <a href=\"https://unsplash.com/@hirmin?utm_source=medium&amp;utm_medium=referral\">Max Kleinen</a> on\u00a0<a href=\"https://unsplash.com/?utm_source=medium&amp;utm_medium=referral\">Unsplash</a></figcaption></figure><p>Transformers are an incredibly powerful tool in the world of NLP. The invention of the transformer was a revolutionary discovery for NLP and the field of machine learning. Today, we see the transformer architecture being used for everything from neural machine translation to image classification. Let's explore how transformers can be used for abstractive text summarization.</p>\n<p>Let\u2019s get started on the tutorial.</p>\n<h4>The first step is to import the various libraries that we will be\u00a0using.</h4>\n<a href=\"https://medium.com/media/408e757204bf8a84dfdd2277537e3dab/href\">https://medium.com/media/408e757204bf8a84dfdd2277537e3dab/href</a><p>We import <em>pandas</em> for the data preprocessing and <em>NumPy</em> for linear\u00a0algebra.</p>\n<p>In this tutorial instead of using <em>PyTorch</em>, I used <em>PyTorch Lightning</em>. We import Dataset and DataLoader from <em>PyTorch</em> so we can create the\u00a0dataset.</p>\n<p>We also import <em>ModelCheckpoint</em> so we can save our model for later\u00a0use.</p>\n<p>From transformers, we will import <em>T5ForConditionalGeneration</em> for the model, <em>AdamW</em> for the optimizer, and <em>T5Tokenizer</em> for the tokenizer.</p>\n<p>The dataset I will be using is the \u201cNEWS SUMMARY\u201d dataset from Kaggle(<a href=\"https://www.kaggle.com/sunnysai12345/news-summary\">https://www.kaggle.com/sunnysai12345/news-summary</a>). <em>Pandas</em> is used to load and preprocess our\u00a0data.</p>\n<a href=\"https://medium.com/media/0b8a35ae057f4e825a9fa5c87b8585c2/href\">https://medium.com/media/0b8a35ae057f4e825a9fa5c87b8585c2/href</a><p>Once the dataframe is loaded we create a new dataframe only using the relevant data needed. I then created a new dataframe and transposed it so the data is column-wise instead of row-wise.</p>\n<p>I also renamed the columns to identify which column has the summary and which one has the source text. Now, drop the nonexistent values and then split the data into a train set and a test\u00a0set.</p>\n<p>Lastly, print out the shape of the dataset making sure that everything looks\u00a0correct.</p>\n<h4>Next, create the PyTorch\u00a0dataset.</h4>\n<p>The code snippet for the dataset is shown\u00a0below:</p>\n<a href=\"https://medium.com/media/6164896957b2e977fef176334c9e1595/href\">https://medium.com/media/6164896957b2e977fef176334c9e1595/href</a><p>As shown in the code snippet above the <em>SummaryDataset</em> class takes four arguments i.e. the tokenizer, the dataframe, source text\u2019s max token length, and summary\u2019s max token length. Using the arguments we will create a text encoding using the tokenizer.</p>\n<p>Now grab the specified row from the dataframe and create the source text\u2019s encoding and then the summary\u2019s encoding. This method eventually returns a dictionary with all the\u00a0data.</p>\n<p>Next, create a PyTorch Lightning Data Module that takes in the test and train dataframe, the source text\u2019s max token length, and the summary\u2019s max token length, the tokenizer, and finally the batch size. In the setup method, the dataset object that we created before is called. Finally, in the dataloader methods, we return the DataLoader of the dataset we\u00a0created.</p>\n<h4>The next step is to define our\u00a0model.</h4>\n<a href=\"https://medium.com/media/bcc32256efe2124c9fabfb8865e05c61/href\">https://medium.com/media/bcc32256efe2124c9fabfb8865e05c61/href</a><p>In the code above I define the model name. The model being used is the \u201ct5-base\u201d model from <em>huggingface. </em>Next, I fetch the pre-trained tokenizer using the specified model name. I then define the number of epochs and our batch\u00a0size.</p>\n<p>Then we build our data module using the batch size, tokenizer, and the train and test data. Next, define the <em>SummaryModel</em> class. I fetch the pre-trained <em>T5ForConditionalGeneration</em> model and call\u00a0it.</p>\n<p>After the model is defined we need to define the training step. First, define the base step method. Grab the input ids, text attention mask, labels, and labels attention mask from the batch and pass all of those arguments into the model, then log the loss. From this base method, we can define the train, validation, and test steps. For the optimizer, return the AdamW optimizer with a learning rate of\u00a0<em>1e-4</em>.</p>\n<h4>Now comes the training of the\u00a0model.</h4>\n<a href=\"https://medium.com/media/4d7ea18b7eaedb23c81cec0dc1850288/href\">https://medium.com/media/4d7ea18b7eaedb23c81cec0dc1850288/href</a><p>In the code above I define the <em>ModelCheckpoint </em>class<em> </em>so it can periodically save checkpoints for future use of the model. Now define a <em>PyTorch Lightning Trainer</em> and pass in the <em>ModelCheckpoint</em> callback, the epochs, GPUs, and the progress bar refresh rate. We fit the trainer with the model and the data module. And there it is, the model is now training!</p>\n<h4>After your model is done training, it\u2019s time to make some predictions!</h4>\n<p>The code snippet is down\u00a0below:</p>\n<a href=\"https://medium.com/media/b1e08a970e904cf12be79609c6b86965/href\">https://medium.com/media/b1e08a970e904cf12be79609c6b86965/href</a><p>First, load the model checkpoint and then freeze the model for a faster prediction. To get the summary, define the summarize function that takes in the text we want to summarize. Into the generate method, pass in the input ids, the attention mask, and the max_length from the generated ids.</p>\n<p><strong>The rest of the hyper-parameters are values that can be fine-tuned.</strong></p>\n<p><strong>If you aren\u2019t happy with the results, try fine-tuning the hyper-parameters.</strong></p>\n<p>Then decode the generated values with the tokenizer which will return the predicted text. After this, return the predictions joined by a space and the summarize function is finished. Now we can test our model with the test dataframe. If you aren\u2019t getting your desired results you can also try training the model for\u00a0longer.</p>\n<p>Here is the snippet of the Result I got\u00a0:</p>\n<blockquote>\n<strong><em>Source Text:</em></strong> The Indian Navy today moved towards acquiring a pin-point ability to attack targets on land with its first test of the land-attack variant of the BrahMos supersonic cruise missile. The missile has a range of 400km.\\xa0 The successive successful launch of the supersonic missile took place at sea off the Andaman and Nicobar islands. This is the first time a land-attack variant of the missile was fired from a warship and also the first sea-to-land missile test in the country. HERE\u2019S ALL YOU NEED TO KNOW:1. The missile fired from the ship squarely hit the specially created land target put up in one of the islands of Andaman and Nicobar. 2. According to officials of the Indo-Russian BrahMos corporation, the missile met all flight parameters during the test where it selected the designated target among the group of targets, hitting it precisely and destroying the target with its tremendous kinetic energy.3. The Navy has already inducted anti-ship versions of the BrahMos on its warships including the Rajput and is integrating them into two other ships of the class. 4. The missiles will also equip the three 7000-ton Kolkata class destroyers currently under construction at the Mazagon Docks Ltd, Mumbai. 5. The Indian Navy began inducting the first version of the BrahMos Missile System in all of its frontline warships from 2005. BrahMos can be launched in single or in a salvo from the ship towards single or different types of targets within an interval of 2\u20132.5 seconds in various trajectories.</blockquote>\n<blockquote>\n<strong><em>Summary Prediction:</em></strong> The Indian Navy on Tuesday launched its first land-attack variant of the BrahMos supersonic cruise missile, which has a range of 400 km. The missile was fired from a warship off the Andaman and Nicobar islands in India. It met all flight parameters during the test where it selected the designated target among the group of targets, hitting it precisely and destroying the target with its tremendous kinetic\u00a0energy.</blockquote>\n<p>Now you have built an abstractive text summarizer using transformers! If you want to learn more about other methods of text summarization, refer to my past article(<a href=\"https://nalinnagar1.medium.com/how-to-make-a-simple-text-summarizer-cf4eb2d0df4a\">https://nalinnagar1.medium.com/how-to-make-a-simple-text-summarizer-cf4eb2d0df4a</a>)</p>\n<p>Let me know what you think of the approach taken in this tutorial. I would be glad to hear ways to improve and any other topics that I should make an article about.<br>Lastly, I am here to learn and share, and any suggestions for improvements are more than\u00a0welcome.</p>\n<p>Otherwise, see you in my next.\u00a0Ciao.</p>\n<img src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=b6967d1892ec\" width=\"1\" height=\"1\" alt=\"\">\n","enclosure":{},"categories":["nlp","pytorch","machine-learning","deep-learning","text-summarization"]},{"title":"How to Make a Simple Text Summarizer","pubDate":"2021-05-29 12:02:46","link":"https://nalinnagar1.medium.com/how-to-make-a-simple-text-summarizer-cf4eb2d0df4a?source=rss-eb61516296cc------2","guid":"https://medium.com/p/cf4eb2d0df4a","author":"Nalin Nagar","thumbnail":"https://cdn-images-1.medium.com/max/1024/0*rmx5RLFLzi9OcH4L","description":"\n<h3>What are Text Summarizers?</h3>\n<p>What are Text Summarizers? How can I make\u00a0one?</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*rmx5RLFLzi9OcH4L\"><figcaption>Photo by <a href=\"https://unsplash.com/@raphaelphotoch?utm_source=medium&amp;utm_medium=referral\">Raphael Schaller</a> on\u00a0<a href=\"https://unsplash.com/?utm_source=medium&amp;utm_medium=referral\">Unsplash</a></figcaption></figure><p>Text summarizers are a heavily researched topic in machine learning and deep learning. The text summarizers we see today can often be complicated and use advanced methods that can be difficult to understand. There are two types of text summarization, extractive summarization(what we will be doing) and abstractive summarization. In extractive summarization, we rank the sentences and form the top-ranked sentences from the source text into a\u00a0summary.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/566/1*92PXylK_ZhYkJPbCmC4Crg.jpeg\"><figcaption><a href=\"https://heartbeat.fritz.ai/extractive-text-summarization-using-neural-networks-5845804c7701\">Heartbeat\u200a\u2014\u200aFritz\u00a0AI</a></figcaption></figure><p>The other type is abstractive summarization. Abstractive summarization is bit more complicated than extractive in that it doesn\u2019t use sentences from the source text but instead creates brand new sentences and a unique\u00a0summary.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/872/1*qo7OzQf2Kf76ElFYH1swNg.png\"><figcaption>Statistical and Analytical Study of Guided Abstractive Text Summarization<br>By Jagadish S. Kallimani, K. Srinivasa, B.\u00a0Reddy</figcaption></figure><p>Let\u2019s get to the tutorial. First, we want to import some of the packages we will be using. These packages will be important in grabbing the data and manipulating it.</p>\n<a href=\"https://medium.com/media/190e6081a8edbf32a62c2173e4ad0f17/href\">https://medium.com/media/190e6081a8edbf32a62c2173e4ad0f17/href</a><p>We will need the request function from <strong>urllib</strong><em> </em>to make requests to URLs for data. Next, we will need <strong>BeautifulSoup </strong>to actually parse the data<strong> </strong>we get from the URL request. We will need <strong>regular expressions</strong> to clean the data from the URL, and <strong>NLTK</strong> for actually doing the text summarization. Lastly, we will need <strong>heapq</strong> for putting our summary in order and presenting it in a readable way. Let's get\u00a0started!</p>\n<a href=\"https://medium.com/media/8a63ed577f77765d09b62980efce1f07/href\">https://medium.com/media/8a63ed577f77765d09b62980efce1f07/href</a><p>Now we will get our text or data to actually summarize. Here we will take the Wikipedia article for toilets. We use request to open the URL and create a BeautifulSoup object which parses all the HTML with the paragraph tag so we can get the actual information. We loop through the object and add it to an empty string. Now we have a variable called \u201cTotalContent\u201d that contains a string with all of our data. Now let's clean our\u00a0data.</p>\n<a href=\"https://medium.com/media/0945fd9a2d659e34bd6ce46400092544/href\">https://medium.com/media/0945fd9a2d659e34bd6ce46400092544/href</a><p>Now we are going to use regular expressions to clean our data. Since the parsed data won\u2019t always be perfect we will sub out some of the unnecessary characters. We use the function \u201csent_tokenize\u201d from NLTK to tokenize each sentence in the text. Then we apply some more regular expressions to make the data readable. In the end, we are able to print out the Wikipedia page\u2019s information on toilets. Let's get to the text summarization part!</p>\n<a href=\"https://medium.com/media/84e3df6e319f2bcf400d0fe2535ff88d/href\">https://medium.com/media/84e3df6e319f2bcf400d0fe2535ff88d/href</a><p>Here we are going to download \u201cpunkt\u201d for using tokenizers and \u201cstopwords\u201d for removing some of the unnecessary words in the text. Stopwords are often removed from a text for better predictions, stopwords contain commonly used words that don\u2019t have much impact on the actual message of the text. We get tokens for each word this time using \u201cword_tokenize\u201d. Then we get our English stopwords for later use. We are looping through each word in the \u201cwords_tokens\u201d and checking if the word is not in stopwords, then if the word passes it is checked if the word is already in the frequency dictionary, if it is then add one to the frequency of that word, if not make a new occurrence of that word in the dictionary. We can print out the frequencies and see what words are used the most. This will be useful for calculating sentence scores later\u00a0on.</p>\n<a href=\"https://medium.com/media/3f98df4e4ab5c90374899a7e58bf25b9/href\">https://medium.com/media/3f98df4e4ab5c90374899a7e58bf25b9/href</a><p>Then we can use this code snippet to normalize all of the frequencies relative to the highest frequency. We get the highest frequency of all the words, then loop through each word and divide its frequency by the maximum, normalizing the frequencies to a value between 0 and\u00a01.</p>\n<a href=\"https://medium.com/media/d66d5626507ed2b89e614490b900fb19/href\">https://medium.com/media/d66d5626507ed2b89e614490b900fb19/href</a><p>Finally, we will summarize the text. First, we create a dictionary that will hold \u201cscores\u201d of a sentence based on its impact on the text. Then loop through each sentence token and loop through the sentence\u2019s words. We check if the word is in the \u201cword_frequencies\u201d dictionary and if it is check its length since we don\u2019t want the sentences to be too long. If the sentence is within the length range the code checks if the sentence is in the sentence scores and if not sets it to the frequency of the word at that time, and if it is in the sentence scores, we will add the frequency of the word to the sentence\u2019s score. After this, the process is\u00a0simple.</p>\n<a href=\"https://medium.com/media/12d387467b73f4a73d6a06dcd59f8898/href\">https://medium.com/media/12d387467b73f4a73d6a06dcd59f8898/href</a><p>We use the <strong>heapq</strong> library to take the 5 sentences with the highest score and add it to one final string. That's your\u00a0summary!</p>\n<p>Here\u2019s the result I got from summarizing the Wikipedia article for\u00a0toilets:</p>\n<blockquote>\u201cA squat toilet (also called \u201csquatting toilet\u201d, \u201cnatural position toilet\u201d, or by many national names) is a toilet of any technology type (i.e.Toilets can be with or without flushing water (flush toilet or dry toilet).Many types of toilets without a water seal (also called dry toilets or \u201cnon-flush toilets\u201d) exist. Another organization which focuses on toilets and sanitation at the global level is the World Toilet Organization which pushed for the creation of a United Nations World Toilet Day. Passenger train toilets, aircraft lavatories, bus toilets, and ships with plumbing often use vacuum toilets.\u201d</blockquote>\n<p>Try this out yourself and see what you\u00a0get!</p>\n<img src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=cf4eb2d0df4a\" width=\"1\" height=\"1\" alt=\"\">\n","content":"\n<h3>What are Text Summarizers?</h3>\n<p>What are Text Summarizers? How can I make\u00a0one?</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*rmx5RLFLzi9OcH4L\"><figcaption>Photo by <a href=\"https://unsplash.com/@raphaelphotoch?utm_source=medium&amp;utm_medium=referral\">Raphael Schaller</a> on\u00a0<a href=\"https://unsplash.com/?utm_source=medium&amp;utm_medium=referral\">Unsplash</a></figcaption></figure><p>Text summarizers are a heavily researched topic in machine learning and deep learning. The text summarizers we see today can often be complicated and use advanced methods that can be difficult to understand. There are two types of text summarization, extractive summarization(what we will be doing) and abstractive summarization. In extractive summarization, we rank the sentences and form the top-ranked sentences from the source text into a\u00a0summary.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/566/1*92PXylK_ZhYkJPbCmC4Crg.jpeg\"><figcaption><a href=\"https://heartbeat.fritz.ai/extractive-text-summarization-using-neural-networks-5845804c7701\">Heartbeat\u200a\u2014\u200aFritz\u00a0AI</a></figcaption></figure><p>The other type is abstractive summarization. Abstractive summarization is bit more complicated than extractive in that it doesn\u2019t use sentences from the source text but instead creates brand new sentences and a unique\u00a0summary.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/872/1*qo7OzQf2Kf76ElFYH1swNg.png\"><figcaption>Statistical and Analytical Study of Guided Abstractive Text Summarization<br>By Jagadish S. Kallimani, K. Srinivasa, B.\u00a0Reddy</figcaption></figure><p>Let\u2019s get to the tutorial. First, we want to import some of the packages we will be using. These packages will be important in grabbing the data and manipulating it.</p>\n<a href=\"https://medium.com/media/190e6081a8edbf32a62c2173e4ad0f17/href\">https://medium.com/media/190e6081a8edbf32a62c2173e4ad0f17/href</a><p>We will need the request function from <strong>urllib</strong><em> </em>to make requests to URLs for data. Next, we will need <strong>BeautifulSoup </strong>to actually parse the data<strong> </strong>we get from the URL request. We will need <strong>regular expressions</strong> to clean the data from the URL, and <strong>NLTK</strong> for actually doing the text summarization. Lastly, we will need <strong>heapq</strong> for putting our summary in order and presenting it in a readable way. Let's get\u00a0started!</p>\n<a href=\"https://medium.com/media/8a63ed577f77765d09b62980efce1f07/href\">https://medium.com/media/8a63ed577f77765d09b62980efce1f07/href</a><p>Now we will get our text or data to actually summarize. Here we will take the Wikipedia article for toilets. We use request to open the URL and create a BeautifulSoup object which parses all the HTML with the paragraph tag so we can get the actual information. We loop through the object and add it to an empty string. Now we have a variable called \u201cTotalContent\u201d that contains a string with all of our data. Now let's clean our\u00a0data.</p>\n<a href=\"https://medium.com/media/0945fd9a2d659e34bd6ce46400092544/href\">https://medium.com/media/0945fd9a2d659e34bd6ce46400092544/href</a><p>Now we are going to use regular expressions to clean our data. Since the parsed data won\u2019t always be perfect we will sub out some of the unnecessary characters. We use the function \u201csent_tokenize\u201d from NLTK to tokenize each sentence in the text. Then we apply some more regular expressions to make the data readable. In the end, we are able to print out the Wikipedia page\u2019s information on toilets. Let's get to the text summarization part!</p>\n<a href=\"https://medium.com/media/84e3df6e319f2bcf400d0fe2535ff88d/href\">https://medium.com/media/84e3df6e319f2bcf400d0fe2535ff88d/href</a><p>Here we are going to download \u201cpunkt\u201d for using tokenizers and \u201cstopwords\u201d for removing some of the unnecessary words in the text. Stopwords are often removed from a text for better predictions, stopwords contain commonly used words that don\u2019t have much impact on the actual message of the text. We get tokens for each word this time using \u201cword_tokenize\u201d. Then we get our English stopwords for later use. We are looping through each word in the \u201cwords_tokens\u201d and checking if the word is not in stopwords, then if the word passes it is checked if the word is already in the frequency dictionary, if it is then add one to the frequency of that word, if not make a new occurrence of that word in the dictionary. We can print out the frequencies and see what words are used the most. This will be useful for calculating sentence scores later\u00a0on.</p>\n<a href=\"https://medium.com/media/3f98df4e4ab5c90374899a7e58bf25b9/href\">https://medium.com/media/3f98df4e4ab5c90374899a7e58bf25b9/href</a><p>Then we can use this code snippet to normalize all of the frequencies relative to the highest frequency. We get the highest frequency of all the words, then loop through each word and divide its frequency by the maximum, normalizing the frequencies to a value between 0 and\u00a01.</p>\n<a href=\"https://medium.com/media/d66d5626507ed2b89e614490b900fb19/href\">https://medium.com/media/d66d5626507ed2b89e614490b900fb19/href</a><p>Finally, we will summarize the text. First, we create a dictionary that will hold \u201cscores\u201d of a sentence based on its impact on the text. Then loop through each sentence token and loop through the sentence\u2019s words. We check if the word is in the \u201cword_frequencies\u201d dictionary and if it is check its length since we don\u2019t want the sentences to be too long. If the sentence is within the length range the code checks if the sentence is in the sentence scores and if not sets it to the frequency of the word at that time, and if it is in the sentence scores, we will add the frequency of the word to the sentence\u2019s score. After this, the process is\u00a0simple.</p>\n<a href=\"https://medium.com/media/12d387467b73f4a73d6a06dcd59f8898/href\">https://medium.com/media/12d387467b73f4a73d6a06dcd59f8898/href</a><p>We use the <strong>heapq</strong> library to take the 5 sentences with the highest score and add it to one final string. That's your\u00a0summary!</p>\n<p>Here\u2019s the result I got from summarizing the Wikipedia article for\u00a0toilets:</p>\n<blockquote>\u201cA squat toilet (also called \u201csquatting toilet\u201d, \u201cnatural position toilet\u201d, or by many national names) is a toilet of any technology type (i.e.Toilets can be with or without flushing water (flush toilet or dry toilet).Many types of toilets without a water seal (also called dry toilets or \u201cnon-flush toilets\u201d) exist. Another organization which focuses on toilets and sanitation at the global level is the World Toilet Organization which pushed for the creation of a United Nations World Toilet Day. Passenger train toilets, aircraft lavatories, bus toilets, and ships with plumbing often use vacuum toilets.\u201d</blockquote>\n<p>Try this out yourself and see what you\u00a0get!</p>\n<img src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=cf4eb2d0df4a\" width=\"1\" height=\"1\" alt=\"\">\n","enclosure":{},"categories":["data-science","nlp","machine-learning"]}]}